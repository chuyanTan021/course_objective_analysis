{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VwEPLXa_oY7l"
   },
   "source": [
    "**Date**: January 2020 \\\\\n",
    "**Purpose**: CSU Department of Atmospheric Science Machine Learning Workshop \\\\\n",
    "**Course Webpage**: https://sites.google.com/rams.colostate.edu/barnesresearchgroup/courses/mltutorial \\\\\n",
    "**Instructors**: Benjamin Toms and Kirsten Mayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWda67n7ouBb"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "The interpretability methods within this code are discussed in more detail in the following paper: \n",
    "\n",
    "Interpretable Neural Networks for Geoscience: Toms, Benjamin A., Elizabeth A. Barnes, and Imme Ebert-Uphoff. “Physically interpretable neural networks for the geosciences: Applications to earth system variability”, https://arxiv.org/abs/1912.01752.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqoyX5-GfXW6"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#Training a Neural Network\n",
    "\n",
    "During this session, we will learn about how to train a neural network. We'll use a task we know the answer to, so we can gain some intuition about how to set up a neural network and not have to worry about whether our task is possible or not.\n",
    "\n",
    "The neural network can achieve 100% accuracy on both the testing and training datasets, so this is the goal you should be shooting for if you decide to tune your model parameters.\n",
    "\n",
    "We'll focus on a few aspects of the model:\n",
    "\n",
    "*   The number of hidden units\n",
    "*   The amount of regularization\n",
    "\n",
    "The number of hidden units dictates how many different patterns of information the neural network can learn to use to connect the input and output. \n",
    "\n",
    "The regularization helps constrain the neural network so that it doesn't overfit to the training data. We'll be using L2 regularization. Higher values of L2 regularization forces the neural network to use a greater number of the inputs, whereas lower values of L2 regularization allow the network to focus on fewer inputs and effectively ignore some of the information we provide. So, not having a high enough L2 regularier can lead to overfitting. \n",
    "\n",
    "In a geospatial sense, higher L2 forces the network to look at broader spatial regions, and might also force the network to include information from points that are spatially correlated, which is helpful for interpretation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7adAS8-g42M"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We will first install packages that we need for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 70279,
     "status": "ok",
     "timestamp": 1587745900586,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxGyQiqej0v5Oem2a-mzfI3Kg0wR7mkUvEhP32K4w=s64",
      "userId": "08898050549780290733"
     },
     "user_tz": 360
    },
    "id": "e-NPdn-4g4Ry",
    "outputId": "f339db2d-386b-471d-fdef-3ab0d4b487e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting innvestigate\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/ce/2138b045dce599515eeecc16cfebc48ee89616c073cdec87503a482f9cd6/innvestigate-1.0.8-py3-none-any.whl (97kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 4.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from innvestigate) (2.10.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from innvestigate) (7.0.0)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from innvestigate) (3.6.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from innvestigate) (1.18.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from innvestigate) (0.16.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from innvestigate) (1.4.1)\n",
      "Collecting keras==2.2.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 12.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->innvestigate) (1.12.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (0.7.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (1.3.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (1.8.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (8.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (19.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->innvestigate) (46.1.3)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->innvestigate) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->innvestigate) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->innvestigate) (3.13)\n",
      "Installing collected packages: keras, innvestigate\n",
      "  Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n",
      "Successfully installed innvestigate-1.0.8 keras-2.2.4\n",
      "Collecting netcdf4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/4f/d49fe0c65dea4d2ebfdc602d3e3d2a45a172255c151f4497c43f6d94a5f6/netCDF4-1.5.3-cp36-cp36m-manylinux1_x86_64.whl (4.1MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1MB 4.7MB/s \n",
      "\u001b[?25hCollecting cftime\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/a7/e32404add6225b1f5a2b9efed6aa5bba918da637c8dd6cf85fe4ad7bfdc4/cftime-1.1.2-cp36-cp36m-manylinux1_x86_64.whl (320kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 52.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from netcdf4) (1.18.3)\n",
      "Installing collected packages: cftime, netcdf4\n",
      "Successfully installed cftime-1.1.2 netcdf4-1.5.3\n",
      "Collecting cmocean\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/02/d0f19b00b252fd972e3daec05be73aa811091528f21b90442a15d6a96d89/cmocean-2.0-py3-none-any.whl (223kB)\n",
      "\u001b[K     |████████████████████████████████| 225kB 4.2MB/s \n",
      "\u001b[?25hInstalling collected packages: cmocean\n",
      "Successfully installed cmocean-2.0\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "proj-data is already the newest version (4.9.3-2).\n",
      "proj-data set to manually installed.\n",
      "The following NEW packages will be installed:\n",
      "  libproj-dev proj-bin\n",
      "0 upgraded, 2 newly installed, 0 to remove and 25 not upgraded.\n",
      "Need to get 232 kB of archives.\n",
      "After this operation, 1,220 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libproj-dev amd64 4.9.3-2 [199 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 proj-bin amd64 4.9.3-2 [32.3 kB]\n",
      "Fetched 232 kB in 1s (235 kB/s)\n",
      "Selecting previously unselected package libproj-dev:amd64.\n",
      "(Reading database ... 144568 files and directories currently installed.)\n",
      "Preparing to unpack .../libproj-dev_4.9.3-2_amd64.deb ...\n",
      "Unpacking libproj-dev:amd64 (4.9.3-2) ...\n",
      "Selecting previously unselected package proj-bin.\n",
      "Preparing to unpack .../proj-bin_4.9.3-2_amd64.deb ...\n",
      "Unpacking proj-bin (4.9.3-2) ...\n",
      "Setting up libproj-dev:amd64 (4.9.3-2) ...\n",
      "Setting up proj-bin (4.9.3-2) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  libgdal-doc\n",
      "The following NEW packages will be installed:\n",
      "  libgeos-dev\n",
      "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
      "Need to get 73.1 kB of archives.\n",
      "After this operation, 486 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgeos-dev amd64 3.6.2-1build2 [73.1 kB]\n",
      "Fetched 73.1 kB in 1s (115 kB/s)\n",
      "Selecting previously unselected package libgeos-dev.\n",
      "(Reading database ... 144601 files and directories currently installed.)\n",
      "Preparing to unpack .../libgeos-dev_3.6.2-1build2_amd64.deb ...\n",
      "Unpacking libgeos-dev (3.6.2-1build2) ...\n",
      "Setting up libgeos-dev (3.6.2-1build2) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.16)\n",
      "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (1.7.0)\n",
      "Collecting cartopy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/92/fe8838fa8158931906dfc4f16c5c1436b3dd2daf83592645b179581403ad/Cartopy-0.17.0.tar.gz (8.9MB)\n",
      "\u001b[K     |████████████████████████████████| 8.9MB 4.4MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: setuptools>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cartopy) (46.1.3)\n",
      "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from cartopy) (1.18.3)\n",
      "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from cartopy) (1.12.0)\n",
      "Collecting pyshp>=1.1.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/16/3bf15aa864fb77845fab8007eda22c2bd67bd6c1fd13496df452c8c43621/pyshp-2.1.0.tar.gz (215kB)\n",
      "\u001b[K     |████████████████████████████████| 225kB 41.8MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: cartopy\n",
      "  Building wheel for cartopy (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cartopy: filename=Cartopy-0.17.0-cp36-cp36m-linux_x86_64.whl size=9713803 sha256=e3ae9fcb86bfb373c0610c7cf337d03c6e2b65c5e93ba340b82d08670862ea27\n",
      "  Stored in directory: /root/.cache/pip/wheels/cd/cf/40/539f798f94e921e94fd376a5f9d213a6febe77754c0b187c73\n",
      "Successfully built cartopy\n",
      "Building wheels for collected packages: pyshp\n",
      "  Building wheel for pyshp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyshp: filename=pyshp-2.1.0-cp36-none-any.whl size=32609 sha256=1b2e53688ffc3672bb08608bdc511c6b55c0716220d0070139be3aca43865540\n",
      "  Stored in directory: /root/.cache/pip/wheels/a6/0c/de/321b5192ad416b328975a2f0385f72c64db4656501eba7cc1a\n",
      "Successfully built pyshp\n",
      "Installing collected packages: pyshp, cartopy\n",
      "Successfully installed cartopy-0.17.0 pyshp-2.1.0\n",
      "Collecting scipy==1.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2MB 162kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.3)\n",
      "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scipy\n",
      "  Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "Successfully installed scipy-1.1.0\n",
      "Requirement already up-to-date: keras-vis in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from keras-vis) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from keras-vis) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: keras in /usr/local/lib/python3.6/dist-packages (from keras-vis) (2.2.4)\n",
      "Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from keras-vis) (0.16.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vis) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis) (1.18.3)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->keras-vis) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vis) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vis) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-vis) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-vis) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis) (7.0.0)\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis) (2.4.1)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->keras-vis) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->keras-vis) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install innvestigate #Package for layerwise relevance propagation\n",
    "!pip install netcdf4 #Package for loading in netcdf4 files\n",
    "!pip install cmocean #Package with beautiful colormaps\n",
    "\n",
    "#All of these installs are for installing the \"cartopy\" package, which is helpful for plotting data on the globe\n",
    "!apt-get install libproj-dev proj-data proj-bin\n",
    "!apt-get install libgeos-dev\n",
    "!pip install cython\n",
    "!pip install shapely cartopy --no-binary shapely --no-binary cartopy\n",
    "\n",
    "!pip install scipy==1.1.0\n",
    "!pip install --upgrade keras-vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QETJEV4whKON"
   },
   "source": [
    "And now we will download the data we will be using.\n",
    "\n",
    "The first file is a netcdf file containing a global grid of sea-surface temperature anomalies from 1880 through December 2018. The mean of the 1961 through 1990 period has been subtracted, which means these are anomalies from the 1961 through 1990 climatology. The time series for each grid cell have also been detrended, so any linear signal of anthropogenic warming have been removed.\n",
    "\n",
    "\n",
    "The second file is a time series of an index that describes how the El Nino Southern Oscillation (ENSO) evolves, also from 1880 through December 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76580,
     "status": "ok",
     "timestamp": 1587745906895,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxGyQiqej0v5Oem2a-mzfI3Kg0wR7mkUvEhP32K4w=s64",
      "userId": "08898050549780290733"
     },
     "user_tz": 360
    },
    "id": "6DvOusqjU--3",
    "outputId": "31df472f-f0b5-4a9e-ad55-f0a5bb0fd1dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-24 16:31:40--  http://portal.nersc.gov/project/dasrepo/AGU_ML_Tutorial/sst.mon.mean.trefadj.anom.detrend.1880to2018.nc\n",
      "Resolving portal.nersc.gov (portal.nersc.gov)... 128.55.201.128\n",
      "Connecting to portal.nersc.gov (portal.nersc.gov)|128.55.201.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://portal.nersc.gov/project/dasrepo/AGU_ML_Tutorial/sst.mon.mean.trefadj.anom.detrend.1880to2018.nc [following]\n",
      "--2020-04-24 16:31:40--  https://portal.nersc.gov/project/dasrepo/AGU_ML_Tutorial/sst.mon.mean.trefadj.anom.detrend.1880to2018.nc\n",
      "Connecting to portal.nersc.gov (portal.nersc.gov)|128.55.201.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 432481167 (412M) [application/x-netcdf]\n",
      "Saving to: ‘sst.mon.mean.trefadj.anom.detrend.1880to2018.nc’\n",
      "\n",
      "sst.mon.mean.trefad 100%[===================>] 412.45M   109MB/s    in 3.9s    \n",
      "\n",
      "2020-04-24 16:31:44 (105 MB/s) - ‘sst.mon.mean.trefadj.anom.detrend.1880to2018.nc’ saved [432481167/432481167]\n",
      "\n",
      "--2020-04-24 16:31:45--  http://portal.nersc.gov/project/dasrepo/AGU_ML_Tutorial/nino34.long.anom.data.txt\n",
      "Resolving portal.nersc.gov (portal.nersc.gov)... 128.55.201.128\n",
      "Connecting to portal.nersc.gov (portal.nersc.gov)|128.55.201.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://portal.nersc.gov/project/dasrepo/AGU_ML_Tutorial/nino34.long.anom.data.txt [following]\n",
      "--2020-04-24 16:31:45--  https://portal.nersc.gov/project/dasrepo/AGU_ML_Tutorial/nino34.long.anom.data.txt\n",
      "Connecting to portal.nersc.gov (portal.nersc.gov)|128.55.201.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15449 (15K) [text/plain]\n",
      "Saving to: ‘nino34.long.anom.data.txt’\n",
      "\n",
      "nino34.long.anom.da 100%[===================>]  15.09K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2020-04-24 16:31:46 (592 KB/s) - ‘nino34.long.anom.data.txt’ saved [15449/15449]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://portal.nersc.gov/project/dasrepo/AGU_ML_Tutorial/sst.mon.mean.trefadj.anom.detrend.1880to2018.nc\n",
    "!wget http://portal.nersc.gov/project/dasrepo/AGU_ML_Tutorial/nino34.long.anom.data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjXG_TqUiVYR"
   },
   "source": [
    "Now, we'll import some packages through various stages of the tutorial. I've broken down each package by what it is useful for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 81334,
     "status": "ok",
     "timestamp": 1587745911654,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxGyQiqej0v5Oem2a-mzfI3Kg0wR7mkUvEhP32K4w=s64",
      "userId": "08898050549780290733"
     },
     "user_tz": 360
    },
    "id": "V4SwBF1lVec0",
    "outputId": "b0609276-0f0c-414a-d98f-fd813d4ccd95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#General Python math functions\n",
    "import math\n",
    "\n",
    "#Loading in data (netcdf files)\n",
    "import h5py\n",
    "\n",
    "#Handling data\n",
    "import numpy as np\n",
    "\n",
    "#Plotting figures\n",
    "import matplotlib.pyplot as plt #Main plotting package\n",
    "from matplotlib import rcParams #For changing text properties\n",
    "import cmocean #A package with beautiful colormaps\n",
    "import cartopy #Useful for plotting maps\n",
    "import cartopy.util #Requires separate import\n",
    "\n",
    "#Making neural networks; Ensure we are using tensorflow 1.15\n",
    "%tensorflow_version 1.x\n",
    "import keras\n",
    "\n",
    "#Interpreting neural networks using LRP\n",
    "import innvestigate #We'll use this for Layerwise Relevance Propagation (LRP)\n",
    "\n",
    "#Interpreting neural networks using saliency\n",
    "import vis.visualization #This is a keras package called keras-vis, so it's very trustworthy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VI7iz1EFw9Hc"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#Data Processing (Prior to Training)\n",
    "\n",
    "\n",
    "Okay! Now it's time to start processing our data.\n",
    "\n",
    "We will first load the datasets using xarray and numpy.\n",
    "\n",
    "We will also pre-process the data before training the neural network. Remember that our data has already been processed to remove climatology and any linear trends, so our job here is easy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djC-q_WulqdF"
   },
   "outputs": [],
   "source": [
    "#Load in the sea-surface temperature data\n",
    "with h5py.File('sst.mon.mean.trefadj.anom.detrend.1880to2018.nc', 'r') as sst_dataset:\n",
    "  sst = np.array(sst_dataset['sst'])\n",
    "  lats = np.array(sst_dataset['lat'])\n",
    "  lons = np.array(sst_dataset['lon'])  \n",
    "\n",
    "#Load in the Nino3.4 index\n",
    "nino_34 = np.loadtxt('nino34.long.anom.data.txt')\n",
    "\n",
    "#Vectorize the sea-surface temperature data by flattening the matrix along the spatial domains.\n",
    "#   We vectorize the data because we will use a fully-connected neural network\n",
    "sst = sst.reshape(sst.shape[0], sst.shape[-2]*sst.shape[-1])\n",
    "\n",
    "#The sst data has 'nan' values where there is land, but we can not train a network with data that has 'nan values\n",
    "# So, we will replace all 'nan' values with zeros\n",
    "sst[np.abs(sst) > 100] = 0\n",
    "\n",
    "#Flatten the Nino3.4 time series (it is currently in a year x month matrix), and remove unwanted fields such as column/row labels\n",
    "nino_34 = nino_34[10:-1,1:].flatten()\n",
    "\n",
    "#Gather only the cases when the Nino3.4 index is greater than 0.5 in magnitude\n",
    "#   We do this so we can focus on months during which ENSO was active (less than 0.5 is inactive)\n",
    "sst = sst[ np.abs(nino_34) > 0.5 ]\n",
    "nino_34 = nino_34[ np.abs(nino_34) > 0.5 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cI3NF-Nul9QR"
   },
   "source": [
    "We will now organize these data for training the neural network. For our purposes, this includes separating the data into a training and validation set.\n",
    "\n",
    "We first define a function that creates a class weight dictionary to help the neural network balance its predictions if the number of samples is disproportionate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-hPxnQF0eYa"
   },
   "outputs": [],
   "source": [
    "#Create a class weight dictionary to help if the classes are unbalanced\n",
    "def class_weight_creator(Y):\n",
    "    class_dict = {}\n",
    "    weights = np.max(np.sum(Y, axis=0)) / np.sum(Y, axis=0)\n",
    "    for i in range( Y.shape[-1] ):\n",
    "        class_dict[i] = weights[i]\n",
    "        \n",
    "    return class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yyz4SJUf0rFe"
   },
   "source": [
    "...and now we organize the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CY3xayjPtCil"
   },
   "outputs": [],
   "source": [
    "#Rename the sst and nino_34 arrays to X (inputs) and Y (labels) to stick with machine learning convention\n",
    "X_all = np.copy(sst)\n",
    "Y_all = np.copy(nino_34)\n",
    "\n",
    "#Change the Y (label) array values to 1 if the sample is an El Nino event and 0 if the sample is a La Nina event\n",
    "Y_all[Y_all > 0] = 1\n",
    "Y_all[Y_all < 0] = 0\n",
    "\n",
    "#Convert the Y array into a categorical array. This means we will create one-hot vector labels for all of the inputs.\n",
    "# The one-hot vectors have an index for each possible output category (two in our case)\n",
    "# A \"1\" is put in the index corresponding to the category to which the sample belongs\n",
    "Y_all = keras.utils.to_categorical(Y_all)\n",
    "\n",
    "#Set the fraction of samples that will be used for validation\n",
    "frac_validate = 0.2\n",
    "\n",
    "#Separate the X and Y matrices into training and validation sub-sets\n",
    "#   For this problem, we will take the last fraction_validate fraction of samples as our validation dataset\n",
    "X_train = X_all[:int(-frac_validate*len(X_all))]\n",
    "Y_train = Y_all[:int(-frac_validate*len(Y_all))]\n",
    "\n",
    "X_validation = X_all[int(-frac_validate*len(X_all)):]\n",
    "Y_validation = Y_all[int(-frac_validate*len(Y_all)):]\n",
    "\n",
    "#Create class weights for training the model. If the dataset is unbalanced, this helps ensure the model\n",
    "# does not simply start guessing the class that has more samples.\n",
    "class_weight = class_weight_creator(Y_train)\n",
    "\n",
    "#Calculate the number of inputs into the neural network (this will be helpful later on)\n",
    "# This value is the number of latitudes times the number of longitudes\n",
    "number_inputs = X_all.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7g_OtjqomiKh"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Training the Neural Network\n",
    "\n",
    "\n",
    "We're getting there! We will now define the structure of our neural network.\n",
    "\n",
    "**IMPORTANT: Every time you train your model, you must re-compile the neural network or it will retain its weights and biases from the last time it was trained. So, run through the below segment of code every time you would like to retrain.**\n",
    "\n",
    "We are using a fully connected network (no convolutional layers), because the purpose of this tutorial is to illustrate interpretability and not the various types of neural networks. Though, the interpretability methods we will use are also applicable to convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82496,
     "status": "ok",
     "timestamp": 1587745912835,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxGyQiqej0v5Oem2a-mzfI3Kg0wR7mkUvEhP32K4w=s64",
      "userId": "08898050549780290733"
     },
     "user_tz": 360
    },
    "id": "H8v0-20SqH5p",
    "outputId": "a1a6b064-9625-4b25-a213-bdd0f7567f83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define the number of hidden nodes within each layer\n",
    "number_nodes_layer_one = 8\n",
    "number_nodes_layer_two = 8\n",
    "\n",
    "#Define the regularization values for each layer -- these defaults lead to a fairly accurate result!\n",
    "l1_regularization_layer_one = 0\n",
    "l2_regularization_layer_one = 25\n",
    "\n",
    "l1_regularization_layer_two = 0\n",
    "l2_regularization_layer_two = 0.01\n",
    "\n",
    "l1_regularization_layer_three = 0\n",
    "l2_regularization_layer_three = 0.01\n",
    "\n",
    "#Define the learning rate of the neural network\n",
    "learning_rate = 0.001\n",
    "\n",
    "###We're getting there! Now we will define the structure of the neural network\n",
    "model = keras.models.Sequential([ \\\n",
    "\n",
    "          keras.layers.Dense(number_nodes_layer_one, input_shape=(int(number_inputs),), \n",
    "                              activation='relu', use_bias=True,\n",
    "                              kernel_initializer='he_normal', bias_initializer='he_normal', \n",
    "                              kernel_regularizer=keras.regularizers.l1_l2(l1=l1_regularization_layer_one, l2=l2_regularization_layer_one)),\n",
    "                \n",
    "          keras.layers.Dense(number_nodes_layer_two, activation='relu', use_bias=True,\n",
    "                              kernel_initializer='he_normal', bias_initializer='he_normal', \n",
    "                              kernel_regularizer=keras.regularizers.l1_l2(l1=l1_regularization_layer_two, l2=l2_regularization_layer_two)),\n",
    "                    \n",
    "          keras.layers.Dense(2, use_bias=True, #Define two output nodes, one for each phase of ENSO\n",
    "                              kernel_initializer='he_normal', bias_initializer='he_normal', \n",
    "                              kernel_regularizer=keras.regularizers.l1_l2(l1=l1_regularization_layer_three, l2=l2_regularization_layer_three)),                                                                           \n",
    "\n",
    "          keras.layers.Activation('softmax')\n",
    "                            \n",
    "                            ])   \n",
    "\n",
    "#We will use the stochastic gradient descent (SGD) optimizer, because we have control over\n",
    "# the learning rate and it is effective for our problem.\n",
    "model.compile(optimizer=keras.optimizers.SGD(lr=learning_rate),\n",
    "              loss = 'categorical_crossentropy', #Our loss function is based on categorical error\n",
    "              metrics=[keras.metrics.categorical_accuracy], #We will print out the categorical accuracy as the network is trained\n",
    "              )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UTZpOkmWnRtU"
   },
   "source": [
    "We will now set some parameters that are important for when we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9dhv-qtvO-j"
   },
   "outputs": [],
   "source": [
    "batch_size = 32 #The number of samples the network sees before it backpropagates (batch size)\n",
    "epochs = 100 #The number of times the network will loop through the entire dataset (epochs)\n",
    "shuffle = True #Set whether to shuffle the training data so the model doesn't see it sequentially \n",
    "verbose = 2 #Set whether the model will output information when trained (0 = no output; 2 = output accuracy every epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mFvvyWLnadp"
   },
   "source": [
    "**This is the moment you have been waiting for.** \n",
    "\n",
    "We will now train our neural network to predict whether the input sea-surface temperature maps are associated with El Nino or La Nina.\n",
    "\n",
    "You will see the model output the accuracy and loss for the training period and the validation period. We validate the model every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 112497,
     "status": "ok",
     "timestamp": 1587745942845,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxGyQiqej0v5Oem2a-mzfI3Kg0wR7mkUvEhP32K4w=s64",
      "userId": "08898050549780290733"
     },
     "user_tz": 360
    },
    "id": "B9KJsrjltNTs",
    "outputId": "c93f4b23-728c-4270-f826-e6125555aacf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 658 samples, validate on 164 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      " - 1s - loss: 175.7508 - categorical_accuracy: 0.9362 - val_loss: 46.7993 - val_categorical_accuracy: 0.9939\n",
      "Epoch 2/100\n",
      " - 0s - loss: 20.7722 - categorical_accuracy: 0.9802 - val_loss: 5.7980 - val_categorical_accuracy: 0.9878\n",
      "Epoch 3/100\n",
      " - 0s - loss: 2.8003 - categorical_accuracy: 0.9848 - val_loss: 1.0411 - val_categorical_accuracy: 0.9878\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.7124 - categorical_accuracy: 0.9833 - val_loss: 0.4874 - val_categorical_accuracy: 0.9878\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4667 - categorical_accuracy: 0.9863 - val_loss: 0.4242 - val_categorical_accuracy: 0.9817\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.4350 - categorical_accuracy: 0.9863 - val_loss: 0.4094 - val_categorical_accuracy: 0.9878\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.4290 - categorical_accuracy: 0.9863 - val_loss: 0.4030 - val_categorical_accuracy: 0.9878\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.4250 - categorical_accuracy: 0.9878 - val_loss: 0.4086 - val_categorical_accuracy: 0.9817\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.4215 - categorical_accuracy: 0.9878 - val_loss: 0.3991 - val_categorical_accuracy: 0.9878\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.4185 - categorical_accuracy: 0.9878 - val_loss: 0.3935 - val_categorical_accuracy: 0.9878\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4154 - categorical_accuracy: 0.9894 - val_loss: 0.3910 - val_categorical_accuracy: 0.9878\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.4128 - categorical_accuracy: 0.9894 - val_loss: 0.3928 - val_categorical_accuracy: 0.9878\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4096 - categorical_accuracy: 0.9894 - val_loss: 0.3837 - val_categorical_accuracy: 0.9878\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4073 - categorical_accuracy: 0.9909 - val_loss: 0.3856 - val_categorical_accuracy: 0.9878\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.4043 - categorical_accuracy: 0.9894 - val_loss: 0.3791 - val_categorical_accuracy: 0.9878\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4012 - categorical_accuracy: 0.9924 - val_loss: 0.3844 - val_categorical_accuracy: 0.9939\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.3996 - categorical_accuracy: 0.9909 - val_loss: 0.3782 - val_categorical_accuracy: 0.9878\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.3975 - categorical_accuracy: 0.9894 - val_loss: 0.3820 - val_categorical_accuracy: 0.9878\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.3953 - categorical_accuracy: 0.9909 - val_loss: 0.3696 - val_categorical_accuracy: 0.9939\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.3928 - categorical_accuracy: 0.9924 - val_loss: 0.3722 - val_categorical_accuracy: 0.9939\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.3911 - categorical_accuracy: 0.9909 - val_loss: 0.3672 - val_categorical_accuracy: 0.9939\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.3881 - categorical_accuracy: 0.9924 - val_loss: 0.3689 - val_categorical_accuracy: 0.9878\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.3861 - categorical_accuracy: 0.9924 - val_loss: 0.3610 - val_categorical_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.3834 - categorical_accuracy: 0.9909 - val_loss: 0.3663 - val_categorical_accuracy: 0.9939\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.3823 - categorical_accuracy: 0.9909 - val_loss: 0.3600 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.3799 - categorical_accuracy: 0.9939 - val_loss: 0.3615 - val_categorical_accuracy: 0.9939\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.3781 - categorical_accuracy: 0.9939 - val_loss: 0.3618 - val_categorical_accuracy: 0.9939\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.3767 - categorical_accuracy: 0.9939 - val_loss: 0.3551 - val_categorical_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.3750 - categorical_accuracy: 0.9939 - val_loss: 0.3564 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.3734 - categorical_accuracy: 0.9924 - val_loss: 0.3560 - val_categorical_accuracy: 0.9939\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.3708 - categorical_accuracy: 0.9939 - val_loss: 0.3562 - val_categorical_accuracy: 0.9939\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.3690 - categorical_accuracy: 0.9939 - val_loss: 0.3525 - val_categorical_accuracy: 0.9939\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.3676 - categorical_accuracy: 0.9939 - val_loss: 0.3477 - val_categorical_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.3658 - categorical_accuracy: 0.9939 - val_loss: 0.3482 - val_categorical_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.3641 - categorical_accuracy: 0.9924 - val_loss: 0.3434 - val_categorical_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.3631 - categorical_accuracy: 0.9954 - val_loss: 0.3430 - val_categorical_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.3608 - categorical_accuracy: 0.9954 - val_loss: 0.3465 - val_categorical_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.3595 - categorical_accuracy: 0.9954 - val_loss: 0.3420 - val_categorical_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.3582 - categorical_accuracy: 0.9939 - val_loss: 0.3427 - val_categorical_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.3567 - categorical_accuracy: 0.9939 - val_loss: 0.3400 - val_categorical_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.3551 - categorical_accuracy: 0.9939 - val_loss: 0.3364 - val_categorical_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.3532 - categorical_accuracy: 0.9924 - val_loss: 0.3378 - val_categorical_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.3529 - categorical_accuracy: 0.9954 - val_loss: 0.3337 - val_categorical_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.3506 - categorical_accuracy: 0.9954 - val_loss: 0.3316 - val_categorical_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.3493 - categorical_accuracy: 0.9954 - val_loss: 0.3352 - val_categorical_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.3485 - categorical_accuracy: 0.9939 - val_loss: 0.3301 - val_categorical_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.3474 - categorical_accuracy: 0.9954 - val_loss: 0.3340 - val_categorical_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.3456 - categorical_accuracy: 0.9954 - val_loss: 0.3267 - val_categorical_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.3439 - categorical_accuracy: 0.9970 - val_loss: 0.3325 - val_categorical_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.3430 - categorical_accuracy: 0.9939 - val_loss: 0.3269 - val_categorical_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.3426 - categorical_accuracy: 0.9954 - val_loss: 0.3293 - val_categorical_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.3406 - categorical_accuracy: 0.9954 - val_loss: 0.3276 - val_categorical_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.3401 - categorical_accuracy: 0.9954 - val_loss: 0.3311 - val_categorical_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.3388 - categorical_accuracy: 0.9954 - val_loss: 0.3213 - val_categorical_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.3385 - categorical_accuracy: 0.9954 - val_loss: 0.3237 - val_categorical_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.3357 - categorical_accuracy: 0.9954 - val_loss: 0.3187 - val_categorical_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.3355 - categorical_accuracy: 0.9954 - val_loss: 0.3177 - val_categorical_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.3344 - categorical_accuracy: 0.9954 - val_loss: 0.3173 - val_categorical_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.3336 - categorical_accuracy: 0.9954 - val_loss: 0.3177 - val_categorical_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.3319 - categorical_accuracy: 0.9954 - val_loss: 0.3221 - val_categorical_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.3317 - categorical_accuracy: 0.9954 - val_loss: 0.3164 - val_categorical_accuracy: 0.9939\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.3301 - categorical_accuracy: 0.9939 - val_loss: 0.3147 - val_categorical_accuracy: 0.9939\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.3294 - categorical_accuracy: 0.9970 - val_loss: 0.3147 - val_categorical_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.3283 - categorical_accuracy: 0.9954 - val_loss: 0.3123 - val_categorical_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.3270 - categorical_accuracy: 0.9954 - val_loss: 0.3111 - val_categorical_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.3262 - categorical_accuracy: 0.9954 - val_loss: 0.3094 - val_categorical_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.3249 - categorical_accuracy: 0.9970 - val_loss: 0.3146 - val_categorical_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.3245 - categorical_accuracy: 0.9924 - val_loss: 0.3123 - val_categorical_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.3231 - categorical_accuracy: 0.9970 - val_loss: 0.3086 - val_categorical_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.3237 - categorical_accuracy: 0.9954 - val_loss: 0.3068 - val_categorical_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.3220 - categorical_accuracy: 0.9970 - val_loss: 0.3043 - val_categorical_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.3201 - categorical_accuracy: 0.9939 - val_loss: 0.3106 - val_categorical_accuracy: 0.9939\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.3210 - categorical_accuracy: 0.9954 - val_loss: 0.3054 - val_categorical_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.3188 - categorical_accuracy: 0.9970 - val_loss: 0.3076 - val_categorical_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.3191 - categorical_accuracy: 0.9954 - val_loss: 0.3067 - val_categorical_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.3168 - categorical_accuracy: 0.9970 - val_loss: 0.3044 - val_categorical_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.3167 - categorical_accuracy: 0.9954 - val_loss: 0.3038 - val_categorical_accuracy: 0.9939\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.3169 - categorical_accuracy: 0.9954 - val_loss: 0.3016 - val_categorical_accuracy: 0.9939\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.3145 - categorical_accuracy: 0.9970 - val_loss: 0.3003 - val_categorical_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.3142 - categorical_accuracy: 0.9939 - val_loss: 0.2979 - val_categorical_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.3139 - categorical_accuracy: 0.9970 - val_loss: 0.2992 - val_categorical_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.3140 - categorical_accuracy: 0.9954 - val_loss: 0.3001 - val_categorical_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.3126 - categorical_accuracy: 0.9954 - val_loss: 0.3037 - val_categorical_accuracy: 0.9939\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.3109 - categorical_accuracy: 0.9970 - val_loss: 0.3035 - val_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.3113 - categorical_accuracy: 0.9954 - val_loss: 0.2931 - val_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.3100 - categorical_accuracy: 0.9954 - val_loss: 0.2984 - val_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.3089 - categorical_accuracy: 0.9954 - val_loss: 0.2931 - val_categorical_accuracy: 0.9939\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.3093 - categorical_accuracy: 0.9954 - val_loss: 0.2935 - val_categorical_accuracy: 0.9939\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.3077 - categorical_accuracy: 0.9970 - val_loss: 0.2928 - val_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.3077 - categorical_accuracy: 0.9954 - val_loss: 0.2955 - val_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.3085 - categorical_accuracy: 0.9954 - val_loss: 0.2935 - val_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.3043 - categorical_accuracy: 0.9954 - val_loss: 0.2947 - val_categorical_accuracy: 0.9939\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.3074 - categorical_accuracy: 0.9954 - val_loss: 0.2982 - val_categorical_accuracy: 0.9939\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.3043 - categorical_accuracy: 0.9939 - val_loss: 0.2903 - val_categorical_accuracy: 0.9939\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.3051 - categorical_accuracy: 0.9939 - val_loss: 0.2954 - val_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.3033 - categorical_accuracy: 0.9954 - val_loss: 0.2966 - val_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.3029 - categorical_accuracy: 0.9954 - val_loss: 0.2875 - val_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.3026 - categorical_accuracy: 0.9954 - val_loss: 0.2882 - val_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.3020 - categorical_accuracy: 0.9954 - val_loss: 0.2953 - val_categorical_accuracy: 0.9939\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.3015 - categorical_accuracy: 0.9954 - val_loss: 0.2936 - val_categorical_accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1768909748>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Train the neural network!\n",
    "model.fit(X_train, Y_train, validation_data=(X_validation, Y_validation), \n",
    "          batch_size=batch_size, epochs=epochs, shuffle=shuffle, verbose=verbose, class_weight=class_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3eGooQs2XM07"
   },
   "source": [
    "\n",
    "We're now finished with training the neural network for identifying the phase of ENSO. That's it for this section! Later on, we'll play with some visualization tools to help you understand how and why the neural network is making its decisions. Fun!\n",
    "\n",
    "\n",
    "\n",
    "#<font color='red'>YOU SHALL NOT PASS...</text>\n",
    "\n",
    "##<font color='red'>...this point so we can finish it in a later section.</text>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZj2sA0hIY6R"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#Neural Network Interpretability\n",
    "During this session, we will learn about how to interpret neural networks. We will focus on two methods that myself and my colleagues have found to hold particular promise in geoscientific applications. There are many other interpretion techniques out there, and so I hope that this offers you a way to enter the domain of interpreting neural networks with confidence as you find the methods that work best for your own projects.\n",
    "\n",
    "We will cover two methods:\n",
    "\n",
    "\n",
    "*   Optimal Input\n",
    "*   Layerwise Relevance Propagation\n",
    "\n",
    "These methods interpret which information within the input the neural network used to make its decision, and projects this information back onto the dimensions of the samples used to train the networks. \n",
    "\n",
    "For more information on their application to geoscientific tasks, refer to the following paper:\n",
    "\n",
    "Toms, Benjamin A., Elizabeth A. Barnes, and Imme Ebbert-Uphoff: Physically Interpretable Neural Networks for the Geosciences: Applications to Earth System Variability; https://arxiv.org/abs/1912.01752\n",
    "\n",
    "Additional references are available at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8h1gTlQ3oO75"
   },
   "source": [
    "\n",
    "#Interpretation Step 1: Optimal Input\n",
    "\n",
    "Okay. We now have a trained model! \n",
    "\n",
    "It's time to apply our interpretability methods to learn something about how and why the neural network makes its decisions.\n",
    "\n",
    "We will first define a function for the optimal input method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9-1djp6-KKJ"
   },
   "outputs": [],
   "source": [
    "def optimal_input(model, input_image, target_output):\n",
    "    \n",
    "    #Need to change the out_loss calculation to use your loss equation\n",
    "    #   Need to use the target_output variable\n",
    "    out_loss = - keras.backend.sum(target_output * keras.backend.log(model.layers[-1].output))\n",
    "\n",
    "    #Calculate the gradients at the input layer WRT your output loss\n",
    "    gradient = keras.backend.gradients(out_loss, [model.input])[0]\n",
    "\n",
    "    #Create a function to iterate the loss and gradient\n",
    "    #Inputs are an image and the learning phase (0 for false)\n",
    "    #Outputs are the loss for the output and gradients WRT input layer\n",
    "    iterate_function = keras.backend.function([model.input, keras.backend.learning_phase()], \n",
    "                             [out_loss, gradient])\n",
    "\n",
    "    number_iterations = 0 #Initialize the number of iterations counter\n",
    "    gradient_increment = 0.01 #Specify how large of a step we will take along the gradient\n",
    "\n",
    "    #Specify the condition for the algorithm to iterate until achieving.\n",
    "    #   For this example I have the algorithm iterate 50,000 times.\n",
    "    #   But you can also change this to be something about the number of iterations or another threshold\n",
    "    while number_iterations < 50000: \n",
    "\n",
    "      #Print statement saying we are still calculating the oi\n",
    "      if number_iterations%10000 == 0:\n",
    "        print('Still calculating the optimal input.')\n",
    "\n",
    "      #Calculate the loss and the gradients at the input layer based on the current stage of the input image\n",
    "      out_loss, out_gradient = iterate_function([input_image, 0])\n",
    "\n",
    "      #Take a step along gradient WRT input -- updates the input slightly towards its optimal input\n",
    "      input_image -= out_gradient*gradient_increment\n",
    "\n",
    "      #Increment the number_of_i\n",
    "      number_iterations += 1\n",
    "        \n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z9cQeRvLqNA_"
   },
   "source": [
    "We will first define some variables that are needed for the optimal input calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vDQHORb2zab-"
   },
   "outputs": [],
   "source": [
    "#Input your input dimensions here -- this is used to generate an all-zero input image; we collected this value earlier in our code\n",
    "input_dimensions = number_inputs\n",
    "\n",
    "#Create the all-zero input image\n",
    "input_image = np.zeros((1, input_dimensions))\n",
    "\n",
    "#Specify the target output; we will target El Nino\n",
    "target_output = [0,1]\n",
    "target_output = keras.backend.variable(target_output) #Convert the the target_output to a Keras variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vjYyLiU1qUGg"
   },
   "source": [
    "We will now call the optimal input function and calculate the optimal input. The \"oi\" variable will hold the optimal input field.\n",
    "\n",
    "The calculation should take about a minute, so be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176678,
     "status": "ok",
     "timestamp": 1587746007040,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhxGyQiqej0v5Oem2a-mzfI3Kg0wR7mkUvEhP32K4w=s64",
      "userId": "08898050549780290733"
     },
     "user_tz": 360
    },
    "id": "dJwHJbo9qYgr",
    "outputId": "bf3481d2-6773-48cb-8160-7bed7bd2a378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "Still calculating the optimal input.\n",
      "Still calculating the optimal input.\n",
      "Still calculating the optimal input.\n",
      "Still calculating the optimal input.\n",
      "Still calculating the optimal input.\n"
     ]
    }
   ],
   "source": [
    "oi = optimal_input(model, input_image, target_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThZfW0oDhEYl"
   },
   "source": [
    "We will now plot the optimal input. As a reminder, the optimal input will show us the sea-surface temperature pattern that makes the neural network most confident that the input is categorized as an El Nino (a positive Nino3.4 index).\n",
    "\n",
    "We will first prepare the oi field by normalizing by the maximum value and adding a cyclic point to the matrix for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CeXZzYY72fF4"
   },
   "outputs": [],
   "source": [
    "#Reshape the matrix to be 2-dimensional (because the input samples were vectorized)\n",
    "oi = np.squeeze(oi)\n",
    "oi = oi.reshape(len(lats),len(lons))\n",
    "\n",
    "#Normalize the image to have a maximum value of 1\n",
    "#  (this isn't necessary all the time, but we do this for our example to make sure we all have similarly scaled output)\n",
    "oi = oi/np.max(np.abs(oi))*1\n",
    "\n",
    "#Now add a cyclic point so we can plot it on the globe\n",
    "oi_cyclic, lons_cyclic = cartopy.util.add_cyclic_point(oi, coord=lons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGbeYgL0kZp0"
   },
   "source": [
    "And now we will make the figure!\n",
    "\n",
    "The figure will take a few seconds to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPMiYL-k3lwW"
   },
   "outputs": [],
   "source": [
    "#Change all future font colors here (changing to light gray for dark mode)\n",
    "rcParams['text.color'] = '0.75'\n",
    "\n",
    "#Generate the figure instance and axis\n",
    "fig1 = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes((0.0,0.0,1.0,1.0),  projection=cartopy.crs.Robinson(central_longitude=225))\n",
    "\n",
    "#Contour-fill the optimal input\n",
    "contour_plot = ax.contourf(lons_cyclic, lats, oi_cyclic, levels=np.linspace(-1,1,100), cmap=cmocean.cm.balance, transform=cartopy.crs.PlateCarree(), extend='both')        \n",
    "\n",
    "#Change some aspects of the figure\n",
    "ax.set_title('Optimal Input', fontsize=50)\n",
    "ax.add_feature(cartopy.feature.LAND, zorder=1, edgecolor='face', facecolor='0.5')\n",
    "ax.set_global()\n",
    "\n",
    "#Create colorbar\n",
    "cax = fig1.add_axes([0.1, -0.15, 0.8, 0.05])\n",
    "cbar = fig1.colorbar(contour_plot, cax=cax, orientation='horizontal', ticks=np.linspace(-1,1,3))\n",
    "cbar.ax.tick_params(labelsize=25, color='0.75', labelcolor='0.75')\n",
    "cax.text(x=0.5, y=1.1, s='SST Anomaly ($^{\\circ}$C)', rotation=0, ha='center', va='bottom', fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xwENnkZYkuVg"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#Interpretation Step 2: Layerwise Relevance Propagation\n",
    "\n",
    "\n",
    "\n",
    "Now that we've seen a composite interpretation of what the neural network has learned, we're going to use layerwise relevance propagation (LRP). Using LRP will help us understand what information a neural network uses from each individual sample to makes its predictions.\n",
    "\n",
    "We first have to slightly modify the neural network before we can use LRP. We remove the softmax layer so that the relevance can be propagated backwards from the pre-softmax output. This is helpful for a few reasons that are discussed at this link: https://github.com/albermax/innvestigate/issues/84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-GBMcJUm67D-"
   },
   "outputs": [],
   "source": [
    "#Remove the softmax layer from the model\n",
    "model_nosoftmax = innvestigate.utils.model_wo_softmax(model)\n",
    "\n",
    "#Create the \"analyzer\", or the object that will generate the LRP heatmaps given an input sample\n",
    "analyzer = innvestigate.create_analyzer('deep_taylor', model_nosoftmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wtq0prAnU4q"
   },
   "source": [
    "We will now create LRP heatmaps for all of the El Nino (positive ENSO phase) samples. We will only save the LRP heatmaps for the samples that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wbB9bgStSmj"
   },
   "outputs": [],
   "source": [
    "#First, create some lists to hold the output\n",
    "LRP_heatmaps_all = []\n",
    "accurate_samples_all = []\n",
    "    \n",
    "#We will process all of the samples, although another good option is to only process the validation samples\n",
    "for sample_ind, sample in enumerate(X_all):\n",
    "\n",
    "      #Do not process any of the La Nina samples; can change this if you would like to see the La Nina samples\n",
    "      if Y_all[sample_ind,1] == 0:\n",
    "        continue\n",
    "    \n",
    "      #Make a print statement so we know how long it is taking to process the samples\n",
    "      if (sample_ind%1000 == 0) & (sample_ind > 0):\n",
    "        print(sample_ind, np.nanmax(dt_all))\n",
    "      \n",
    "      #Make the prediction from the model to see if the model correctly identifies the samples as El Nino\n",
    "      sample_prediction = np.argmax(model.predict(sample[np.newaxis,...]))\n",
    "\n",
    "      #Continue if the sample is correctly predicted as El Nino...\n",
    "      if sample_prediction == 1:\n",
    "        LRP_heatmap = analyzer.analyze(sample[np.newaxis,...])\n",
    "\n",
    "        LRP_heatmaps_all.append(LRP_heatmap)\n",
    "        accurate_samples_all.append(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wtgx0BxEqvQS"
   },
   "source": [
    "Now that we have collected the LRP heatmaps, we will do some post-processing before making a figure. W\n",
    "\n",
    "\n",
    "We'll normalize each LRP heatmap by its maximum value so that each heatmap has equal weight when it is composited. We will then make the composite LRP map to compared to optimal input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_Xtj2EXfdvR"
   },
   "outputs": [],
   "source": [
    "#Convert the list to an array to make processing simpler and reshape it into a 2-D map (our inputs were vectorized)\n",
    "LRP_heatmaps_all = np.array(LRP_heatmaps_all)\n",
    "LRP_heatmaps_all = LRP_heatmaps_all.reshape(LRP_heatmaps_all.shape[0], len(lats), len(lons))\n",
    "\n",
    "#Add a cyclic point to the heatmaps for future plotting\n",
    "LRP_heatmaps_all_cyclic, lons_cyclic = cartopy.util.add_cyclic_point(LRP_heatmaps_all, coord=lons)\n",
    "\n",
    "#Normalize each heatmap to have a maximum value of 1 so all samples can be compared equally\n",
    "LRP_heatmaps_all_cyclic = LRP_heatmaps_all_cyclic/np.nanmax(LRP_heatmaps_all_cyclic, axis=(-2,-1))[:,np.newaxis,np.newaxis]\n",
    "\n",
    "#Now take the mean across all samples to make a composite...\n",
    "LRP_heatmaps_mean_cyclic = np.nanmean(LRP_heatmaps_all_cyclic, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MdCjIPnspGM"
   },
   "source": [
    "We will now plot a composiet of the LRP heatmaps. This composite is useful for comparing to the optimal input and identifying which regions of the optimal input are likely most important. While the two methods are not directly related, the LRP composite commonly exhibits similar patterns to the optimal input, but helps isolate which regions of the optimal input are particularly important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8EVpBaY-B8n"
   },
   "outputs": [],
   "source": [
    "#Generate the figure instance and axis\n",
    "fig1 = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes((0.0,0.0,1.0,1.0),  projection=cartopy.crs.Robinson(central_longitude=225))\n",
    "\n",
    "#Contour-fill the composite relevance\n",
    "contour_plot = ax.contourf(lons_cyclic, lats, LRP_heatmaps_mean_cyclic, levels=np.linspace(0,0.75,100), transform=cartopy.crs.PlateCarree(),  cmap=cmocean.cm.ice, zorder=0, extend='max')\n",
    "\n",
    "#Change some aspects of the figure\n",
    "ax.set_title('Composite Relevance', fontsize=50)\n",
    "ax.add_feature(cartopy.feature.LAND, zorder=1, edgecolor='face', facecolor='0.5')\n",
    "ax.set_global()\n",
    "\n",
    "#Create colorbar\n",
    "cax = fig1.add_axes([0.1, -0.15, 0.8, 0.05])\n",
    "cbar = fig1.colorbar(contour_plot, cax=cax, orientation='horizontal', ticks=np.linspace(-1,1,3))\n",
    "cbar.ax.tick_params(labelsize=25, color='0.75', labelcolor='0.75')\n",
    "cax.text(x=0.5, y=1.1, s='Relevance (unitless)', rotation=0, ha='center', va='bottom', fontsize=25, color='0.75')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V6onK7GitE--"
   },
   "source": [
    "We will now plot the optimal input, LRP composite, and observed composite El Nino sea-surface temperature pattern.\n",
    "\n",
    "First, we need to generate a composite of the El Nino samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2V7s5EEMQkB"
   },
   "outputs": [],
   "source": [
    "#We first need to create the composite of all El Nino samples\n",
    "elnino_composite = np.mean( sst[Y_all[:,1] == 1], axis=0).reshape(len(lats),len(lons)) #Gather only the El Nino samples, and take the mean\n",
    "\n",
    "#Re-scale the El Nino composite to have a maximum value of 1, as we did with our optimal input field\n",
    "elnino_composite = elnino_composite / np.nanmax(np.abs(elnino_composite))\n",
    "\n",
    "#Add a cyclic point so we can plot on a map\n",
    "elnino_composite_cyclic, lons_cyclic = cartopy.util.add_cyclic_point(elnino_composite, coord=lons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49W45dXXtQRI"
   },
   "source": [
    "...and now we can make the figure comparing optimal input, LRP, and the observed El Nino composite. This figure is large, so you will have to scroll to see it all.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3zBqQ-nWNi2J"
   },
   "outputs": [],
   "source": [
    "#Axes instance for the optimal input \n",
    "fig1 = plt.figure(figsize=(20,10))\n",
    "\n",
    "ax = plt.axes((0.0,0.5,0.5,0.5),  projection=cartopy.crs.Robinson(central_longitude=225))\n",
    "\n",
    "#Contour-fill the optimal input\n",
    "contour_plot_1 = ax.contourf(lons_cyclic, lats, oi_cyclic, levels=np.linspace(-1,1,100), cmap=cmocean.cm.diff, transform=cartopy.crs.PlateCarree(), extend='both')        \n",
    "\n",
    "#Change some aspects of the figure\n",
    "ax.set_title('Optimal Input', fontsize=50)\n",
    "ax.add_feature(cartopy.feature.LAND, zorder=1, edgecolor='face', facecolor='0.5')\n",
    "ax.set_global()\n",
    "\n",
    "#Create colorbar\n",
    "cax = fig1.add_axes([0.06, 0.41, 0.38, 0.025])\n",
    "cbar = fig1.colorbar(contour_plot_1, cax=cax, orientation='horizontal', ticks=np.linspace(-1,1,3))\n",
    "cbar.ax.tick_params(labelsize=30, color='0.75', labelcolor='0.75')\n",
    "cax.text(x=0.5, y=1.1, s='Optimized SST Anomaly ($^{\\circ}$C)', rotation=0, ha='center', va='bottom', fontsize=30)\n",
    "\n",
    "\n",
    "#Axes instance for the composite LRP heatmap\n",
    "ax = plt.axes((0.0,-0.22,0.5,0.5),  projection=cartopy.crs.Robinson(central_longitude=225))\n",
    "\n",
    "#Contour-fill the composite relevance\n",
    "contour_plot_2 = ax.contourf(lons_cyclic, lats, LRP_heatmaps_mean_cyclic, levels=np.linspace(0,0.75,100), transform=cartopy.crs.PlateCarree(),  cmap=cmocean.cm.ice, zorder=0, extend='max')\n",
    "\n",
    "#Change some aspects of the figure\n",
    "ax.set_title('Composite Relevance', fontsize=50)\n",
    "ax.add_feature(cartopy.feature.LAND, zorder=1, edgecolor='face', facecolor='0.5')\n",
    "ax.set_global()\n",
    "\n",
    "#Create colorbar\n",
    "cax = fig1.add_axes([0.06, 0.41 - 0.57 - 0.145, 0.38, 0.025])\n",
    "cbar = fig1.colorbar(contour_plot_2, cax=cax, orientation='horizontal', ticks=[0])\n",
    "cbar.ax.tick_params(labelsize=30, color='0.75', labelcolor='0.75')\n",
    "cax.text(x=0.5, y=1.1, s='Normalized Relevance (unitless)', rotation=0, ha='center', va='bottom', fontsize=30)\n",
    "\n",
    "\n",
    "#Axes instance for the observed El Nino pattern\n",
    "ax = plt.axes((0.0,-0.94,0.5,0.5),  projection=cartopy.crs.Robinson(central_longitude=225))\n",
    "\n",
    "#Contour-fill the composite El Nino observations\n",
    "contour_plot_3 = ax.contourf(lons_cyclic, lats, elnino_composite_cyclic, levels=np.linspace(-1,1,100), cmap=cmocean.cm.diff, transform=cartopy.crs.PlateCarree(), extend='both')        \n",
    "\n",
    "#Change some aspects of the figure\n",
    "ax.set_title('Composite Observations', fontsize=50)\n",
    "ax.add_feature(cartopy.feature.LAND, zorder=1, edgecolor='face', facecolor='0.5')\n",
    "ax.set_global()\n",
    "\n",
    "#Create colorbar\n",
    "cax = fig1.add_axes([0.06, 0.41 - 0.57*2 - 0.145*2 - 0.01, 0.38, 0.025])\n",
    "cbar = fig1.colorbar(contour_plot_3, cax=cax, orientation='horizontal', ticks=np.linspace(-1,1,3))\n",
    "cbar.ax.tick_params(labelsize=30, color='0.75', labelcolor='0.75')\n",
    "cax.text(x=0.5, y=1.1, s='Observed SST Anomaly ($^{\\circ}$C)', rotation=0, ha='center', va='bottom', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTKKdl1PtWci"
   },
   "source": [
    "Great! It looks like the optimal input and LRP agree well. LRP tells us that, at least in a composite sense, the neural network looks at the tropical Pacific to identify El Nino events. This is reassuring, since we know that El Nino is best characterized by warm surface temperature anomalies within the central and eastern Pacific.\n",
    "\n",
    "We can make things even more interesting by looking at the LRP heatmaps for each individual sample. We will do this in the below code. We'll use some of the arrays we created back when we first ran LRP over all of our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_HOnVzG-Ndl9"
   },
   "outputs": [],
   "source": [
    "#First, remap our samples back into maps (we vectorized them for training)\n",
    "accurate_samples_all = np.array(accurate_samples_all)\n",
    "accurate_samples_all = accurate_samples_all.reshape(accurate_samples_all.shape[0],len(lats),len(lons))\n",
    "\n",
    "#Add a cyclic point for plotting\n",
    "accurate_samples_all_cyclic, lons_cyclic = cartopy.util.add_cyclic_point(accurate_samples_all, coord=lons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJqZFMy9twGX"
   },
   "source": [
    "And now we can make the plots! We will plot the sea-surface temperatures in fill and overlay the LRP heatmaps as open contours. This will tell us which regions of sea-surface temperature anomalies the neural network used to correctly classify each individual sample.\n",
    "\n",
    "\n",
    "You can change the sample that is plotted by changing the \"sample_to_plot\" variable to another index. \n",
    "\n",
    "Lighter open contours represent higher relevance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AV-g5NXGP05z"
   },
   "outputs": [],
   "source": [
    "#NOTE: You can change the index that you would like to plot using the below variables.\n",
    "#   Changes these indices will change the sample that you plot, so you can get a good feeling for the variability of the LRP heatmaps across samples\n",
    "sample_to_plot = 1\n",
    "\n",
    "#Create a list of colors for the LRP relevance\n",
    "colors = ['0.01','0.275','0.65','0.825','1']\n",
    "\n",
    "fig1 = plt.figure(figsize=(20,10))\n",
    "\n",
    "#Axes instance for the global plot of SST with the relevance overlain in open contours\n",
    "ax1 = plt.axes((0.0,0.5,0.5,0.5),  projection=cartopy.crs.Robinson(central_longitude=225))\n",
    "\n",
    "#Contour-fill the SST and open contour the relevance\n",
    "contour_plot_1 = ax1.contourf(lons_cyclic, lats, accurate_samples_all_cyclic[sample_to_plot], levels=np.linspace(-2,2,100), cmap=cmocean.cm.balance, transform=cartopy.crs.PlateCarree(), extend='both')        \n",
    "contour_plot_2 = ax1.contour(lons_cyclic, lats, LRP_heatmaps_all_cyclic[sample_to_plot], levels=np.linspace(0.2,1.0,5), transform=cartopy.crs.PlateCarree(),  colors=colors, zorder=2)\n",
    "\n",
    "#Change some aspects of the figure\n",
    "ax1.set_title('Global', fontsize=50)\n",
    "ax1.add_feature(cartopy.feature.LAND, zorder=1, edgecolor='face', facecolor='0.5')\n",
    "ax1.set_global()\n",
    "\n",
    "#Axes instance for the zooms on the tropical pacific\n",
    "ax2 = plt.axes((0.0,0.0,0.5,0.5),  projection=cartopy.crs.Robinson(central_longitude=225))\n",
    "\n",
    "#Contour-fill the SST and open contour the relevance\n",
    "contour_plot_3 = ax2.contourf(lons_cyclic, lats, accurate_samples_all_cyclic[sample_to_plot], levels=np.linspace(-2,2,100), cmap=cmocean.cm.balance, transform=cartopy.crs.PlateCarree(), extend='both')        \n",
    "contour_plot_4 = ax2.contour(lons_cyclic, lats, LRP_heatmaps_all_cyclic[sample_to_plot], levels=np.linspace(0.2,1.0,5), transform=cartopy.crs.PlateCarree(),  colors=colors, zorder=2)\n",
    "\n",
    "#Change some aspects of the figure\n",
    "ax2.set_title('Tropical Pacific Zoom', fontsize=50)\n",
    "ax2.add_feature(cartopy.feature.LAND, zorder=1, edgecolor='face', facecolor='0.5')\n",
    "ax2.set_extent([105, 290, -22.5, 22.5], crs=cartopy.crs.PlateCarree())\n",
    "\n",
    "#Create colorbar\n",
    "cax = fig1.add_axes([0.55, 0.225, 0.0165, 0.7])\n",
    "cbar = fig1.colorbar(contour_plot_3, cax=cax, orientation='vertical', ticks=np.linspace(-2,2,3))\n",
    "cbar.ax.tick_params(labelsize=30, color='0.75', labelcolor='0.75')\n",
    "cax.text(x=-0.1, y=0.5, s='SST Anomaly ($^{\\circ}$C)', rotation=90, ha='right', va='center', fontsize=30)\n",
    "\n",
    "#Create contour color legend\n",
    "plt.text(1.65,0.275,'Relevance Contour Legend', transform=ax1.transAxes, ha='center', fontsize=30, color='1')\n",
    "plt.text(1.65,0.15,'Lower Relevance', transform=ax1.transAxes, ha='center', fontsize=30, color='0')\n",
    "plt.text(1.65,0.05,'Higher Relevance', transform=ax1.transAxes, ha='center', fontsize=30, color='0.8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GO4Ay2qtKaoF"
   },
   "source": [
    "#Interpretation Step 3: Saliency Maps\n",
    "\n",
    "Okay, now that we have intuition for what backwards optimization and layerwise relevance propagation offer us, we'll explore saliency maps.\n",
    "\n",
    "Remember that saliency maps tell us which regions within the input increase the value of some output that we decide we want to increase. So, for our case, we're going to try to increase the probability that the input is associated with an El Nino event.\n",
    "\n",
    "For similar reasons to LRP, we will increase the value of the pre-softmax node for the El Nino class. This is because increasing the probability for the El Nino class could simply mean decreasing the probability for the La Nina class. But, for this case, we want to know which features within the input make an El Nino more likely because of the patterns of El Nino, not because of a lack of a La Nina pattern. These are subtly different questions.\n",
    "\n",
    "Okay, now for coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6Ja31XKLJiB"
   },
   "outputs": [],
   "source": [
    "class_to_investigate = 0 #Identify the class for which we will calculate the saliency map\n",
    "sample_index_to_input = 500 #Set the index of the sample we would like to analyze\n",
    "sample_to_input = X_train[sample_index_to_input][np.newaxis,...] #Collect the input sample we wish to analyze\n",
    "output_index = 1 #Specify the output index you want to calculate the saliency map for \n",
    "                 #0 corresponds to La Nina, 1 corresponds to El Nino\n",
    "\n",
    "#Identify the layer from which we'll optimize the specified class.\n",
    "# Remember that we will use the layer before the softmax activation.\n",
    "# If you want to check out what the model layers look like in keras, use the command:\n",
    "# print(model.layers)\n",
    "layer_to_use = model.layers[-2]\n",
    "\n",
    "#Remove the softmax layer from the model\n",
    "model_nosoftmax = innvestigate.utils.model_wo_softmax(model)\n",
    "\n",
    "#Create the \"analyzer\", or the object that will generate the LRP heatmaps given an input sample\n",
    "analyzer = innvestigate.create_analyzer('gradient', model_nosoftmax, neuron_selection_mode=\"index\")\n",
    "\n",
    "#Collect the saliency map for the sample we've specified\n",
    "saliency_map = analyzer.analyze(sample_to_input, output_index)\n",
    "\n",
    "#Reshape the saliency map...into a map (the output is at first in the same shape is our input vectors)\n",
    "saliency_map = saliency_map.reshape(saliency_map.shape[0],len(lats),len(lons))[0]\n",
    "sample_to_input = sample_to_input.reshape(sample_to_input.shape[0],len(lats),len(lons))[0]\n",
    "\n",
    "#Add a cyclic point for plotting\n",
    "saliency_map_cyclic, lons_cyclic = cartopy.util.add_cyclic_point(saliency_map, coord=lons)\n",
    "sample_to_input_cyclic, lons_cyclic = cartopy.util.add_cyclic_point(sample_to_input, coord=lons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqD3Lnxvqfua"
   },
   "source": [
    "Okay, now we'll plot the saliency map. \n",
    "\n",
    "If you specified the saliency map to be with respect to index 0 of the output vector, which corresponds to La Nina, then:\n",
    "\n",
    "*   Positive saliency shows where the SST should be increased to make the pattern more representative of La Nina\n",
    "*   Negative saliency shows where the SST should be decreased to make the pattern more representative of La Nina\n",
    "\n",
    "...and if you specified the saliency map to be with respect to index 1 of the output vector, which corresponds to El Nino, then:\n",
    "\n",
    "*   Positive saliency shows where the SST should be increased to make the pattern more representative of El Nino\n",
    "*   Negative saliency shows where the SST should be decreased to make the pattern more representative of El Nino\n",
    "\n",
    "Regions with higher magnitudes of saliency show regions that increase \n",
    "\n",
    "If the absolute value of the saliency values are higher, that means that the value of the output index is more sensitive to changes in SST values at that location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwSWFN5EeVXR"
   },
   "outputs": [],
   "source": [
    "#Generate the figure instance and axis\n",
    "fig1 = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes((0.0,0.0,1.0,1.0),  projection=cartopy.crs.Robinson(central_longitude=225))\n",
    "\n",
    "#Contour-fill the composite relevance\n",
    "contour_plot = ax.contourf(lons_cyclic, lats, saliency_map_cyclic, levels=np.linspace(-0.001,0.001,100), \n",
    "                           transform=cartopy.crs.PlateCarree(),  cmap=cmocean.cm.balance, zorder=0, extend='both')\n",
    "\n",
    "#Change some aspects of the figure\n",
    "ax.set_title('Saliency Map for Sample ' + str(sample_index_to_input), fontsize=50)\n",
    "ax.add_feature(cartopy.feature.LAND, zorder=1, edgecolor='face', facecolor='0.5')\n",
    "ax.set_global()\n",
    "\n",
    "#Create colorbar\n",
    "cax = fig1.add_axes([0.1, -0.15, 0.8, 0.05])\n",
    "cbar = fig1.colorbar(contour_plot, cax=cax, orientation='horizontal', ticks=np.linspace(-0.001,0.001,3))\n",
    "cbar.ax.tick_params(labelsize=25, color='0.75', labelcolor='0.75')\n",
    "# cax.text(x=0.5, y=1.1, s='Saliency', rotation=0, ha='center', va='bottom', fontsize=25, color='0.75')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7tV9Sm6IvLlp"
   },
   "source": [
    "We'll now overlay the saliency atop the actual SST anomalies for the chosen sample. We can then better understand why the neural network tells us which regions of SST anomalies we should increase or decrease to make the pattern look more like El Nino or La Nina.\n",
    "\n",
    "Note that the solid open contours represent positive saliency and the dashed open contours represent negative saliency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "quN8IK-Svj3F"
   },
   "outputs": [],
   "source": [
    "#Generate the figure instance and axis\n",
    "fig1 = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes((0.0,0.0,1.0,1.0),  projection=cartopy.crs.Robinson(central_longitude=225))\n",
    "\n",
    "#Contour-fill the composite relevance\n",
    "contour_plot = ax.contourf(lons_cyclic, lats, sample_to_input_cyclic, levels=np.linspace(-2,2,100), \n",
    "                           transform=cartopy.crs.PlateCarree(),  cmap=cmocean.cm.balance, zorder=0, extend='both')\n",
    "ax.contour(lons_cyclic, lats, saliency_map_cyclic, levels=np.linspace(0.0002,0.001,3), \n",
    "                           transform=cartopy.crs.PlateCarree(),  cmap='Greys_r')\n",
    "ax.contour(lons_cyclic, lats, saliency_map_cyclic, levels=np.linspace(-0.001,-0.0002,3), \n",
    "                           transform=cartopy.crs.PlateCarree(),  cmap='Greys', linestyles='--')\n",
    "\n",
    "#Change some aspects of the figure\n",
    "ax.set_title('Saliency Map (contour) & SST Anomalies (fill) for sample ' + str(sample_index_to_input), fontsize=30)\n",
    "ax.add_feature(cartopy.feature.LAND, zorder=1, edgecolor='face', facecolor='0.5')\n",
    "ax.set_global()\n",
    "\n",
    "#Create colorbar\n",
    "cax = fig1.add_axes([0.1, -0.15, 0.8, 0.05])\n",
    "cbar = fig1.colorbar(contour_plot, cax=cax, orientation='horizontal', ticks=np.linspace(-2,2,3))\n",
    "cbar.ax.tick_params(labelsize=25, color='0.75', labelcolor='0.75')\n",
    "cax.text(x=0.5, y=1.1, s='SST Anomaly ($^{\\circ}$C)', rotation=0, ha='center', va='bottom', fontsize=25, color='0.75')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dpMHQMn1uj5"
   },
   "source": [
    "Something you might notice is that saliency is noisier than the relevance from layerwise relevance propagation. \n",
    "\n",
    "The noise within saliency makes sense, because the saliency is calculated separately for each input feature (which in this case would be each grid point). Relevance, on the other hand, focuses on the entire map at once, and organizes the relevance across each feature simultaneously. \n",
    "\n",
    "So, for LRP, the more dominant features of the patterns identified by the neural network will be more prominent than the minor features, but this is not guaranteed using saliency.\n",
    "\n",
    "Saliency is in itself still a very valuable interpretation method! Each method we covered has its own uses and benefits, and so it is up to you as a scientist to determine which one is the most useful for your case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PYu9x7E-uHOc"
   },
   "source": [
    "#Congratulations! \n",
    "\n",
    "You are now well on your way to being an expert in neural network interpretability.\n",
    "\n",
    "We have covered three of the most powerful interpretation methods. Using these three methods and your newfound confidence in interpreting neural networks, you can delve deeper and discover how these and other methods can uncover connections within your own geoscientific data.\n",
    "\n",
    "We hope you enjoyed this session!\n",
    "\n",
    "-Ben and Kirsten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4w2Fv3lv2jy"
   },
   "source": [
    "#References for Additional Reading\n",
    "\n",
    "##Optimal Input\n",
    "**Within Geoscience**: Interpretable Neural Networks for Geoscience: Toms, Benjamin A., Elizabeth A. Barnes, and Imme Ebert-Uphoff. “Physically interpretable neural networks for the geosciences: Applications to earth system variability”, https://arxiv.org/abs/1912.01752.\n",
    "\n",
    "**Within Geoscience**: McGovern, A., Lagerquist, R., Gagne, D. J., Jergensen, G. E., Elmore, K. L., Home-yer, C. R., & Smith, T.(2019).Making the black box more transparent:Understanding the physical implications of machine learning.Bulletin of theAmerican Meteorological Society.\n",
    "\n",
    "**Within Geoscience**: Gagne, D. J., Haupt, S. E., Nychka, D. W., & Thompson, G.   (2019).   Interpretabledeep learning for spatial analysis of severe hailstorms.Monthly Weather Re-view,147(8), 2827–2845.\n",
    "\n",
    "**Computer Science Paper**: Olah, C., Mordvintsev, A., & Schubert, L.    (2017).    Feature visualization. Distill, 2(11).\n",
    "\n",
    "**Computer Science Paper**: Simonyan, K., Vedaldi, A., & Zisserman, A.(2013).Deep inside convolutionalnetworks:  Visualising image classification models and saliency maps.arXivpreprint arXiv:1312.6034.\n",
    "\n",
    "**Computer Science Paper**: Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., & Lipson, H.   (2015).   Understandingneural networks through deep visualization.arXiv preprint arXiv:1506.06579.\n",
    "\n",
    "\n",
    "\n",
    "##Layerwise Relevance Propagation\n",
    "**Within Geoscience**: Interpretable Neural Networks for Geoscience: Toms, Benjamin A., Elizabeth A. Barnes, and Imme Ebert-Uphoff. “: Applications to earth system variability”, https://arxiv.org/abs/1912.01752.\n",
    "\n",
    "**Fundamental Theory**: Bach, S., Binder, A., Montavon, G., Klauschen, F., M ̈uller, K.-R., & Samek, W.(2015).On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation.PloS one,10(7), e0130140.\n",
    "\n",
    "**Fundamental Theory**: Montavon, G., Lapuschkin, S., Binder, A., Samek, W., & M ̈uller, K.-R.   (2017).   Ex-plaining nonlinear classification decisions with deep taylor decomposition.Pat-tern Recognition,65, 211–222.\n",
    "\n",
    "\n",
    "##General Interpretability\n",
    "**Intro to Feature Visualization**:    Olah, C., et al. “Feature Visualization.” Distill, 2017, https://distill.pub/2017/feature-visualization/.\n",
    "\n",
    "**Book on Explainable AI**: W Samek, G Montavon, A Vedaldi, LK Hansen, KR Müller (Eds.) Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, Springer LNCS 11700, 2019\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ann_ENSO_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
